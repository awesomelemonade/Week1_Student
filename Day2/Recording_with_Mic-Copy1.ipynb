{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording With Your Microphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Make sure you have followed the instructions in the [Microphone](https://github.com/LLCogWorks2018/Microphone) repository so that the code in this notebook will work!  We want to be able to match songs played into your microphone with mp3 files that were already fingerprinted and stored in a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, recording audio through the microphone has a little bit different of a process for fingerprinting than mp3 files.  Your microphone stores the audio on buffer frames, which is just an area of RAM made for temporary storage. Buffers are typically used when there is a difference between the rate at which data is received and the rate at which it can be processed. More can be read about them [here](https://en.wikipedia.org/wiki/Data_buffer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to talk abut first obtaining the audio frames from the function of the microphone class called `record_audio` and then reading in the frames as numerical data. \n",
    "\n",
    "That is:\n",
    "\n",
    "```python\n",
    "from microphone import record_audio\n",
    "listen_time = 5  # seconds\n",
    "frames, sample_rate = record_audio(listen_time )\n",
    "```\n",
    "The `sample_rate` variable is the frequency at which the computer initially sampled the sound via the microphone which is stored because it will give us a corresponding time for each sampling which you can see in the last line of the code at the bottom of this cell.\n",
    "\n",
    "The `frames` variable points to bytes in memory and we are going to read that memory expecting 16-bit integer-values. We will store these frames as NumPy arrays and combine them into a single array with the following two lines of code.\n",
    "\n",
    "```python\n",
    "# read in the recorded audio, saved as a numpy array of 16-bit integers\n",
    "audio_data = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "\n",
    "# the corresponding time (sec) for each sample\n",
    "time = np.arange(len(audio_data)) * sample_rate\n",
    "```\n",
    "\n",
    "Each frame (`for i in frames`) is being translated into a NumPy array of 16-bit integers via the function `np.frombuffer`\n",
    "Because the microphone does not continuously record and has a break each time there is a new memory frame, the data needs to get concatenated using the horizontal stack function (placing the arrays end to end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try running this to record audio for 5 seconds\n",
    "from microphone import record_audio\n",
    "listen_time = 5  # seconds\n",
    "frames, sample_rate = record_audio(listen_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this to hear it!\n",
    "from microphone import play_audio\n",
    "play_audio(frames, listen_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the digitizes audio data as a numpy array\n",
    "audio_data = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "time = np.arange(len(audio_data)) * sample_rate # corresponding time (sec) for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "audio_data = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "time = np.arange(len(audio_data)) * sample_rate # corresponding time (sec) for each sample\n",
    "\n",
    "fix, axs = plt.subplots(1, 2, figsize = (9,3))\n",
    "x = np.linspace(0, 2, 2 * sample_rate / (sample_rate / 10))\n",
    "print(len(audio_data))\n",
    "y = audio_data[:2*sample_rate]\n",
    "y = y[::int(sample_rate / 10)]\n",
    "\n",
    "axs[0].plot(x,y);\n",
    "axs[0].set_title('low sampling rate');\n",
    "axs[1].plot(np.linspace(0,2,2*sample_rate), audio_data[:2*sample_rate]);\n",
    "axs[1].set_title( 'computers sampling rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
